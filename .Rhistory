lm1
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
lm1
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
lm1
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
lm1
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
lm1
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
summary(lm1)
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
summary(lm1)
plot(lm1, which = c(1))
---
output:
html_document: default
pdf_document: default
---
# Regression and model validation
Week 2
The data used is from a study which investigates the relationship between teaching, learning approaches and exam results of the students.
First we import the data which we wrangled and saved locally in the first part of the exercise. The data is set to a variable ```lrn14``` using read.table.
```{r}
lrn14 <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
```
We also need to import few dependancies for later use:
```{r}
library(dplyr)
library(GGally)
library(ggplot2)
```
By using ```str()``` we can have a look at the structure of the data:
```{r}
str(lrn14)
```
The output gives us meta information about the data in general and about each column itself: amount of rows and colums, name of the variables, data type and the first values. There's seven variables gender, global attitude toward statistics, exam points and three variables "deep" (deep questions), "surf" (surface questions), "stra" (strategic questions) which are composed of means calculated from answering various questions. These three, in the same order as mentioned previously, stand for "intention to maximize understanding, with a true commitment to learning", "memorizing without understanding, with a serious lack of personal engagement in the learning process" and "the ways students organize their studying".
The questions were measured with a scale from 1 to 5 with (1 = disagree, 5 = agree). The data covers answers from 183 participants of which 67% were female and had a mean age of 25.6 years. Observations with 0 exam points are excluded from the data in the wrangling part of the exercise.
Using ```dim()``` we get an output which gives as the dimensions of the dataset.
```{r}
dim(lrn14)
```
The ```ggpairs()``` functions provides us a matrix of plots which consists of density plots, bar plot, histograms, scatter plots, correlation coefficients and box plots. These plots represent all the possible combinations of the variables.
Using the dataset with ```ggpairs()``` we generate a graphical overview:
```{r}
p <- ggpairs(lrn14, mapping = aes(col = gender), lower = list(combo = wrap("facethist", bins = 20)))
p
```
And with ```summary()``` we get a summary of the variables:
```{r}
summary(lrn14)
```
Just looking at the density plots they give us an rough idea how each variable is distributed. All the variables seem to be close to normally distributed expect for "age" and "deep". The scale for age is from 17 to 55 so it makes sense for the density plot to be heavily distributed to the young side since the participants of the survey are students. In the "deep" variable there is quite interesting bias towards agreeing to a lot to the questions. From the summary we see that the mean to answering "deep questions" is 3.68.
A regression model can be calculated with ```lm()```. As for the formula we will be using "Points" as dependent variable and "Attitude", "stra" and "deep" for explanatory variables. Also a summary of the regression model is generated with ```summary()```:
```{r}
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = lrn14)
lm1
```
The intercept is the value of y ("Points") when all the x ("Attitude","stra","deep") are 0. The other values are the slope in the linear regression model.
```{r}
summary(lm1)
```
The residuals are difference between the observed value of the dependant variable and the predicted value. Each data point has a residual. The residuals should be normally distributed and their sum should always be 0. Residuals can reveal unexplained patterns in data which is fitted to the model.
The coefficients show us the estimate, standard error, t-value and p-value. Standard error is an estimate of the standard deviation of the coefficient estimate. T-value is estimate divided by standard error. The p-value shows the probability of observing A t-value larger than the one presented. P-value basically indicates if there's evidence against the null hypothesis. Low p-value
indicates strong evidence against the null hypothesis and high p-value indicates weak evidence or no evidence against the null hypothesis.
The output also gives us a "signif. codes" which make it easier to interpret the results with just a glance. In this case "Attitude" received p-value of under 0.01 which means there is strong evidence that the null hypothesis does not hold. This means that it is unlikely that "Attitude" does not correlate with "points". "stra" had p-value between 0.05 and 0.1 which indicates weak evidence that the null hypothesis does not hold. Variable "deep" does not have statistically signifant relationship with the target variable.
Residual standard error is the standard deviation of the residuals.
R-squared tells us how close the data is to the fitted regression line. The higher the R-squared, the better the model fits the data. If the R-squared was 100% the fitted values would all be on the fitted regression line. Difference between multiple and adjusted R-squared is that adjusted R-squared takes the phenomenon of R-squared automatically increasing when more explanatory variables are added to the model. The adjusted R-squared is at 19.51% which indicates that the data points will be quite scattered around the fitted regression line. This indicates that producing predictions with this model would be somewhat inaccurate.
F-statistic is variaton between sample means divided by variance within the samples. The p-value in the f-statistics indicate that atleast some of the results are statistically significant. If the p-value here would indicate insignificance we couldn't reject the null hypothesis.
Next we fit the model again without variable "deep":
```{r}
lm1 <- lm(formula = Points ~ Attitude + stra, data = lrn14)
lm1
```
```{r}
summary(lm1)
```
Without the variable "deep" we get similar results with a bit higher p-values for "Attitude" and "stra" but still within the same signifiance codes as before. Also the r-squared and f-statistics stay relatively the same.
Usin ```qplot()``` we generate three diagnostics plots: "Residuals vs Fitted values", "Normal QQ-plot" and "Residuals vs Leverage". We give the model as parameter with a vector of "indexes"
to choose the right plots.
```{r}
plot(lm1, which = c(1,2,5))
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
summary(lm1)
plot(lm1, which = c(1,2,5))
---
output:
html_document: default
pdf_document: default
---
# Regression and model validation
Week 2
The data used is from a study which investigates the relationship between teaching, learning approaches and exam results of the students.
First we import the data which we wrangled and saved locally in the first part of the exercise. The data is set to a variable ```lrn14``` using read.table.
```{r}
lrn14 <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
```
We also need to import few dependancies for later use:
```{r}
library(dplyr)
library(GGally)
library(ggplot2)
```
By using ```str()``` we can have a look at the structure of the data:
```{r}
str(lrn14)
```
The output gives us meta information about the data in general and about each column itself: amount of rows and colums, name of the variables, data type and the first values. There's seven variables gender, global attitude toward statistics, exam points and three variables "deep" (deep questions), "surf" (surface questions), "stra" (strategic questions) which are composed of means calculated from answering various questions. These three, in the same order as mentioned previously, stand for "intention to maximize understanding, with a true commitment to learning", "memorizing without understanding, with a serious lack of personal engagement in the learning process" and "the ways students organize their studying".
The questions were measured with a scale from 1 to 5 with (1 = disagree, 5 = agree). The data covers answers from 183 participants of which 67% were female and had a mean age of 25.6 years. Observations with 0 exam points are excluded from the data in the wrangling part of the exercise.
Using ```dim()``` we get an output which gives as the dimensions of the dataset.
```{r}
dim(lrn14)
```
The ```ggpairs()``` functions provides us a matrix of plots which consists of density plots, bar plot, histograms, scatter plots, correlation coefficients and box plots. These plots represent all the possible combinations of the variables.
Using the dataset with ```ggpairs()``` we generate a graphical overview:
```{r}
p <- ggpairs(lrn14, mapping = aes(col = gender), lower = list(combo = wrap("facethist", bins = 20)))
p
#Anton JyrkiÃ¤inen
#9.11.2018
#Data used http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt
# installing of packages need only to be run once
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# structure of the data
# The output shows us some meta data about the data in general and about each column:
# amount of rows and columns, name of each column, data type and the first values.
str(lrn14)
# dimensions of the data
# Returns the number of rows and colums
dim(lrn14)
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging.
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging.
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging.
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# Define a new dataset 'learning2014'. Get only the columns we want using select() and one_of()
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
# Exclude observations where the exam points are 0 by using filter()
learning2014 <- filter(learning2014, Points > 0)
# Dimensions of new dataset
dim(learning2014)
# Setting and printing working directory
setwd("C:/Users/Anton/Documents/IODS-project/")
getwd()
# Saving the dataset locally
write.table(learning2014,file="learning2014.txt")
# Testing saved dataset. Shows same results as the dim(learning2014)
importedDataset <- read.table("C:/Users/Anton/Documents/IODS-project/learning2014.txt")
dim(importedDataset)
#sandbox
lm1 <- lm(formula = Points ~ Attitude + stra + deep, data = learning2014)
summary(lm1)
lm1 <- lm(formula = Points ~ Attitude + stra, data = learning2014)
summary(lm1)
plot(lm1, which = c(1,2,5))
